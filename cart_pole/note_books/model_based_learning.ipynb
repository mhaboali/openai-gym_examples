{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import random, os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "from statistics import median, mean\n",
    "from collections import Counter\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_folderPath = ''\n",
    "\n",
    "## Learing rate for training the model\n",
    "LR = 1e-3\n",
    "## Create the OpenAI gym environment\n",
    "env = gym.make(\"CartPole-v0\")\n",
    "## Make sure everything is reset at the beginning\n",
    "env.reset()\n",
    "## Number of steps per episode\n",
    "goal_steps = 500\n",
    "## Desired goal value to be used for filtering the outliers\n",
    "score_threshold = 50\n",
    "## Number of episodes for the training\n",
    "training_episodes_num = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_training_data():\n",
    "    # Store the training data in terms of[OBS, MOVES] per each step\n",
    "    training_data = []\n",
    "    # Record all scores per each episode for doing some analysis later:\n",
    "    scores = []\n",
    "    # Record only the filtered scores that met our threshold:\n",
    "    accepted_scores = []\n",
    "    # Here we generate our training data by iterating through however many episodes we want:\n",
    "    for _ in range(training_episodes_num):      ## EPISODES PARENT LOOP\n",
    "        # Initial score for the episode\n",
    "        score = 0\n",
    "        # Store all observations and the corresponding actions per each episode\n",
    "        episode_memory = []\n",
    "        # Store the previous observation that we saw, because we store in the memory the current action with the previous observation\n",
    "        # [prev_observ, action] represents one item of our training data\n",
    "        prev_observation = []\n",
    "        # Here we iterate over number of steps per each episode, to generate the training data\n",
    "        for _ in range(goal_steps):            \n",
    "            # Show the cart-pole window\n",
    "            # env.render()\n",
    "            # Pick an initial action at the beginning of each step.\n",
    "            action = random.randrange(0,2)\n",
    "            # Apply this action on the Agent and take the corresponding observation, the termination state, and reward value.\n",
    "            observation, reward, done, info = env.step(action)\n",
    "            \n",
    "            # Check if there is at least one previous observation, store the resulted action based on it.\n",
    "            if len(prev_observation) > 0 :\n",
    "                # Here we store the previous observation and the resulted action from it.\n",
    "                episode_memory.append([prev_observation, action])\n",
    "            # The current observation at this iteration will be the previous observation for the next iteration.\n",
    "            prev_observation = observation\n",
    "            # Accumlate the episode score value by adding this step's reward value.\n",
    "            score+=reward\n",
    "            # Here is the cart-pole reached a forbidden situation, so this episode is finished now and let's try a new episode after resetting\n",
    "            if done: break\n",
    "\n",
    "        # Here we're do some filtering on the score data, \n",
    "        # IF our score is higher than our threshold, we'd like to save every move we made\n",
    "        # Here all we're doing is reinforcing the score, we're trying only to inforce the machine \n",
    "        # to learn with those good situations\n",
    "        if score >= score_threshold:\n",
    "            # Storing the filtered scores to do some analysis on this training data.\n",
    "            accepted_scores.append(score)\n",
    "            # Here we store the training data items from the episode memory\n",
    "            for data in episode_memory:\n",
    "                # data is a training item [observation, action]\n",
    "                # Here we determine the output value for this accepted score\n",
    "                if data[1] == 1:        # Here the action is to go right for example\n",
    "                    output = [0,1]\n",
    "                elif data[1] == 0:      # Here the action is to go left for example.\n",
    "                    output = [1,0]\n",
    "                    \n",
    "                # saving our training data [prev_observation, outputAction]\n",
    "                training_data.append([data[0], output])\n",
    "\n",
    "        # reset env to play again\n",
    "        env.reset()\n",
    "        # save overall scores\n",
    "        scores.append(score)\n",
    "    \n",
    "    # Update our game_memory training data to be used later if we need\n",
    "    new_training_data = np.array(training_data)\n",
    "    old_training_data = np.load(example_folderPath + 'data/saved.npy') \\\n",
    "    if os.path.isfile(example_folderPath + 'data/saved.npy') else [] #get data if exist\n",
    "    np.save(example_folderPath + 'data/saved.npy',np.append(old_training_data, new_training_data))\n",
    "    \n",
    "    # some stats here, to further illustrate the neural network magic!\n",
    "    print('Average accepted score:',mean(accepted_scores))\n",
    "    print('Median score for accepted scores:',median(accepted_scores))\n",
    "    print(Counter(accepted_scores))\n",
    "    \n",
    "    return training_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network_model(input_size):\n",
    "    \"\"\"\n",
    "    shape: list of `int`. An array or tuple representing input data shape.\n",
    "            It is required if no placeholder is provided. First element should\n",
    "            be 'None' (representing batch size), if not provided, it will be\n",
    "            added automatically.\n",
    "    \"\"\"\n",
    "    # input_size is the size of the training data array.\n",
    "    network = input_data(shape=[None, input_size, 1], name='input')\n",
    "\n",
    "    # Hidden layers(Fully connected layers with 20% dropout and relu activation function)\n",
    "    network = fully_connected(network, 128, activation='relu')\n",
    "    network = dropout(network, 0.8)\n",
    "\n",
    "    network = fully_connected(network, 256, activation='relu')\n",
    "    network = dropout(network, 0.8)\n",
    "\n",
    "    network = fully_connected(network, 512, activation='relu')\n",
    "    network = dropout(network, 0.8)\n",
    "\n",
    "    # network = fully_connected(network, 512, activation='relu')\n",
    "    # network = dropout(network, 0.8)\n",
    "\n",
    "    network = fully_connected(network, 256, activation='relu')\n",
    "    network = dropout(network, 0.8)\n",
    "\n",
    "    network = fully_connected(network, 128, activation='relu')\n",
    "    network = dropout(network, 0.8)\n",
    "    # Output layer(targets layer) with softmax activation and 2 output nodes for the 2 actions\n",
    "    network = fully_connected(network, 2, activation='softmax')\n",
    "\n",
    "    network = regression(network, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets')\n",
    "    model = tflearn.DNN(network, tensorboard_dir='log')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(training_data, model=False):\n",
    "    # Training data structure is [[[prev_observ], output], ... n training example]\n",
    "    # And we need it in (n, 1) format to be compatible with the input layer neurals\n",
    "    # So we'll use reshape function to reach this format, by creating a 3D matirx(x,y,z) to be Array of 2D matrices\n",
    "    # x: rows number which's number of all training examples\n",
    "    # y: row number of each sub-matrix, which's number of observations per each matrix\n",
    "    # z: columns number of each sub-matrix, which's number of number of examples to be taken\n",
    "    \"\"\"\n",
    "    reshape(-1,...) : It simply means that it is an unknown dimension and we want numpy to figure it out. \n",
    "    And numpy will figure this by looking at the 'length of the array and remaining dimensions'\n",
    "    \"\"\"\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    X = np.array([i[0] for i in training_data], dtype=np.float32).reshape(-1,len(training_data[0][0]),1)\n",
    "    y = [i[1] for i in training_data]\n",
    "    if not model:   # if we don't have a pre-trained model, create a new one.\n",
    "        model = neural_network_model(input_size = len(X[0]))    # Takes number of the training examples\n",
    "    \"\"\"\n",
    "    one epoch = one forward pass and one backward pass of all the training examples\n",
    "    batch size = the number of training examples in one forward/backward pass. \n",
    "    The higher the batch size, the more memory space you'll need.\n",
    "    number of iterations = number of passes, each pass using [batch size] number of exam\n",
    "\n",
    "    WHY several epochs:\n",
    "    Neural networks are typically trained using an iterative optimization method (most of the time, gradient descent), \n",
    "    which often needs to perform several passes on the training set to obtain good results.\n",
    "    \"\"\"\n",
    "    model.fit({'input': X}, {'targets': y}, n_epoch=3, snapshot_step=500, show_metric=True, run_id='cart_pole_learning')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(training_data, model):\n",
    "    scores = []\n",
    "    choices = []\n",
    "    for each_game in range(150):\n",
    "        score = 0\n",
    "        episode_memory = []\n",
    "        prev_obs = []\n",
    "        env.reset()\n",
    "        for _ in range(goal_steps):\n",
    "            # env.render()\n",
    "\n",
    "            if len(prev_obs)==0:\n",
    "                action = random.randrange(0,2)\n",
    "            else:\n",
    "                action = np.argmax(model.predict(prev_obs.reshape(-1,len(prev_obs),1))[0])\n",
    "\n",
    "            choices.append(action)\n",
    "                    \n",
    "            new_observation, reward, done, info = env.step(action)\n",
    "            prev_obs = new_observation\n",
    "            episode_memory.append([new_observation, action])\n",
    "            score+=reward\n",
    "            if done: break\n",
    "\n",
    "        scores.append(score)\n",
    "    # print(score_threshold)\n",
    "    return scores, choices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    training_data = generate_training_data()\n",
    "    model = train_model(training_data)\n",
    "    scores, choices = test_model(training_data, model)\n",
    "    print('Average Score:',sum(scores)/len(scores))\n",
    "    print('choice 1:{}  choice 0:{}'.format(choices.count(1)/len(choices),choices.count(0)/len(choices)))\n",
    "    model.save(example_folderPath + \"models/\" + str(sum(scores)/len(scores)) + \".model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()\n",
    "exit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
